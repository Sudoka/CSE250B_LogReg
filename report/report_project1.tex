\documentstyle[nips]{article}

\title{Logistic Regression with L$_2$ Regularization}

\author{Adrian Guthals, David Larson, Jason Yao \\
CSE 250B: Project \#1 \\
University of California, San Diego \\
}


\begin{document}

\maketitle


%\begin{abstract}
%The abstract still needs to be written. It should provide a brief summary of the studied problem and our methods. Also, it state our results with a concise explanation of their meaning (good and/or bad).
%\end{abstract}


% Headings:
%   Section: all caps (e.g. FIRST)
%   Subsection: all caps (e.g. SECOND)
%   Subsubsection: initial caps (e.g. Third)



%-----------------------------------------------------------------------------
% INTRODUCTION
%-----------------------------------------------------------------------------
\section{INTRODUCTION}
\label{sec:intro}

Machine Learning (ML) is a sub-discipline of Artificial Intelligence (AI) that focuses on the development and analysis of methods that produce models from data. An often referenced example application of ML is email spam filtering, but there is a wide variety of real-world problems where ML has been successful used, from object detection using a Microsoft Kinect sensor \cite{Kinect} to forecasting of power output from a photovoltaic solar farm \cite{solar}.

ML algorithms are plentiful in number, but some are more suitable than others depending on the type of problem. Logistic regression is a ML algorithm well-suited to problems involving a set of real-valued inputs and a binary (Bernoulli) output. A real-world example of such a problem is whether a baseball player will hit a home run based on a collection of statistics (e.g. batting average, height, weight). The statistics are the real-valued inputs, whether he hits a home run is the binary output (1=yes, 0=no), and the probability of whether a player hits a home run is the determined using logistic regression. 

In this paper we analyze logistic regressions capability for classification learning using a previously study as a baseline \cite{t-logistic}. Aside from recreating the previous study's results, we also extend their work to comparing two gradient-based optimization methods for use in conjuction with the logistic regression: Stochastic Gradient Descent (SGD) and Limited-memory Broyden-Fletcher-Goldfarb-Shannon (L-BFGS).



%-----------------------------------------------------------------------------
% DESIGN OF ALGORITHMS
%-----------------------------------------------------------------------------
\section{DESIGN AND ANALYSIS OF ALGORITHMS}
\label{sec:algorithms}

\subsection{LOGISTIC REGRESSION}
Given a set of real-valued features $x$ with binary labels $y$ (a training set), we can define logistic regression model as: 
\begin{equation}
    p_i = p( y_i | x_i ; \beta )  = \frac{1}{1 + \textrm{exp}-[\sum_{j=0}^d \beta_j x_ij]}
\end{equation}
where $d$ is the dimensionality of a training example, and $\beta_j$ are parameters of the regression. To learn the logistic regression, we need deteremine $\vec\beta$ such that the Log Conditional Likelihood (LCL) is maximized. In more formal notation:
\begin{equation}
   \widehat{B} = \textrm{argmax}_{\beta} \textrm{LCL}
\end{equation}
where LCL is defined as:
\begin{equation}
    \textrm{LCL} = \sum_{i:y_i=1} log (p_i) + \sum_{i:y_i=0} log (1-p_i)
\end{equation}
and is maximized when its derivative with respect to each parameter $\beta_j$ is zero. For a single example the partial derivative of the LCL is:
\begin{equation}
    \frac{\partial}{\partial \beta_j} log L(\beta ; x, y) = (y - p) x_j
\end{equation}


\subsection{L2 REGULARIZATION}
In order to prevent overfitting of machine learning, a penalty was imposed to regulate the values of the parameters. A regularization constant $\mu$ was introduced into the LCL objective function:

\begin{equation}
    \hat{B} = \textrm{argmax}_{\beta} LCL - \mu||\beta||_2^2
\end{equation}
where $||\beta||_2^2$ is the $L_2$ norm of the parameter vector. With this revision the derivative of the LCL becomes:

\begin{equation}
    \frac{\partial}{\partial \beta_j} [ log p( y | x ; \beta) -\mu \sum_{j=0}^d \beta_j^2 ] = (y - p) x_j - 2 \mu \beta_j
\end{equation}


\subsection{GRADIENT-BASED OPTIMIZATION}
To efficiently maximize LCL, two gradient-based optimization methods are used: SGD and L-BFGS. The SGD was coded from scratched in Matlab while we used the popular minFunc toolbox \cite{minFunc} for the L-BFGS. For each of these algorithms, the input training data is formatted as a set of $n$ examples ($x_1, \ldots , x_n$) where each $x_i$ is a real-valued vector of $d$ features. Each $x_i$ is correlated to a binary (Bernoulli) outcome $y_i$ by a global parameter vector $\beta$ of length $d+1$. 


\subsubsection{SGD} 
Our SGD implementation first randomized the order of input examples to avoid repeated computation of random numbers and partitioned the input data into $x_1 \ldots x_k$ \emph{training} examples and $x_{k+1} \ldots x_n$ \emph{validation} examples. Then sequential mini-batches of size $\kappa < k$ taken from the training set were used to update the parameter vector $\beta$ (initialized to all zero values) by the following equation. The constant $\mu$ quantifies the trade-off between maximizing likelihood and minimizing parameter values for $L_2$ Regularization.

\begin{equation}
    \beta := \beta + \frac{\lambda}{\kappa}\,[-2 \mu \beta + \sum_{i=1}^{\kappa} (y_i - p_i)\,x_i]
\end{equation}

After each update of $\beta$, absolute change in the objective $\widehat{\beta}$ was computed over all validation examples with the following function.

\begin{equation}
    \widehat{\beta} = \mu \|\beta\|_2 + \sum_{i=k+1}^{n}{-\log(p_i^{y_i}(1 - p_i)^{1-y_i})}
\end{equation}

Convergence was reached when change in the objective reached a value less than $\omega$. Convergence was also reached if the total number of epochs was greater than $\varepsilon$. With this configuration, the time to run the SGD is O(nd).

To improve the performance of the SGD, cross-validation was added. The pseudo-code for SGD with cross-validation is as follows:
\begin{enumerate}
    \item Initialize all parameter values $\beta_j$
    \item Initialize all conditional probabilities $p_i$
    \item Initialize the objective function and its difference value
    \item Randomly divide the example set into two groups: testing set of m rows and validation set of (n-m) rows
    \item while(objective function difference $\geq$ theshold AND number of epochs $<$ maximum epochs allowed
    \begin{enumerate}
        \item Randomly pick a sample of s rows out of the testing set
        \item Update $\beta_j$ for all features
        \item Update the objective function
    \end{enumerate}
\end{enumerate}

The algorithm was run ten times to generate 10 vectors of parameters. The ten vectors of parameters were averaged to calculate one vector with cross-validation. The result cross-validated vector was used to calculate the test error and its variance over all the instances. The test error was defined as the average value of the loss function:
\begin{equation}
        \textrm{test error} = \sum_{i=1}^{n} -log(y_i | x_i ; \beta )
\end{equation}


\subsubsection{L-BFGS}
Limited-memory Broyden-Fletcher-Goldfarb-Shannon (L-BFGS) is a quasi-Newton optimization method used to find local extrema. L-BFGS provides performance gains over Newton's method by approximating (instead of solving directly) the Hessian matrix of the objective function.



%-----------------------------------------------------------------------------
% DESIGN OF EXPERIMENTS
%-----------------------------------------------------------------------------
\section{DESIGN OF EXPERIMENTS}
\label{sec:experiments}

\subsection{PRE-PROCESSING TRAINING DATA}
normalization, concatation?

\subsubsection{USPS-N}
Digit 9 vs other digits

\subsubsection{Web}
anything special?



\subsection{HYPERPARAMETERS}

Stochastic gradient descent (SGD) and  were each implemented in Matlab to maximize the total conditional log likelihood of each training data set. In brief, SGD incorporated a fixed learning rate $\lambda$ to control the change in log likelihood, which was averaged over random mini-batches of size $\kappa$. To control over-fitting, logistic regression was used and change in the objective function was evaluated on a separate validation dataset containing 30\% of all training examples selected at random. Convergence was reached when change in the objective function was less than $\omega$ or the total number of epochs was greater than $\varepsilon$ (which ever came first). (Add brief overview of L-BFGS and cite MinFunc's implementation)



\subsubsection{Learning Rate}
How did we determine $\lambda$ (the learning rate).

\subsubsection{Regularization}
How did we determine $\mu$ (the regularization constant).




%-----------------------------------------------------------------------------
% RESULTS OF EXPERIMENTS
%-----------------------------------------------------------------------------
\section{RESULTS OF EXPERIMENTS}
\label{sec:results}

Results of experiments. Comparison of methods and data sets.

\subsection{USPS-N}
How did SGD and L-BFGS perform on the USPS-N data sets.

\subsection{WEB}
How did SGD and L-BFGS perform on the Web data sets.


\subsubsection{Figures} 

\begin{figure}[h]
\vspace{1in}
\caption{Comparison of SGD and L-BFGS for USPS-N (left) and Web (right) data sets.}
\end{figure}

\begin{table}[t]
\caption{Hyperparameters.}
\label{tab-hyperparameters}
\begin{center}
\begin{tabular}{lll}
& $\lambda$  & $\mu$
\\ \hline \\
SGD & 1.0  & 1.0 \\
SGD & 0.1  & 1.0 \\
SGD & 0.01 & 1.0 \\
\end{tabular}
\end{center}
\end{table}



%-----------------------------------------------------------------------------
% FINDINGS AND LESSONS LEARNED
%-----------------------------------------------------------------------------
\section{FINDINGS AND LESSONS LEARNED}
\label{sec:conclusion}

Findings and lessons learned.



%-----------------------------------------------------------------------------
% BIBLIOGRAPHY
%-----------------------------------------------------------------------------
\bibliographystyle{IEEEtran}
\bibliography{sources}


\end{document}
